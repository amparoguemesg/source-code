{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "slideshow": {
     "slide_type": "-"
    },
    "tags": []
   },
   "source": [
    "## Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "tags": []
   },
   "source": [
    "-------------- \n",
    "### Comments and observations  \n",
    "------------------------------\n",
    "Created by Amparo Guemes (1 April 2023). Adapted from original code with objects for easiness in reuse \n",
    "\n",
    "Code for processing evoked CAP recorded using tungsten microwires coated with PEDOT from sciatic nerve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "\"hide-input\""
    ]
   },
   "outputs": [],
   "source": [
    "import IPython\n",
    "# IPython.Application.instance().kernel.do_shutdown(True)\n",
    "\n",
    "%matplotlib widget\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import datetime\n",
    "import pycwt\n",
    "import statistics\n",
    "import random\n",
    "import pickle\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import sklearn as sk\n",
    "import tkinter as tk\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn import decomposition\n",
    "from sklearn.decomposition import PCA\n",
    "from tkinter import *\n",
    "from tkinter import ttk\n",
    "from sklearn import preprocessing\n",
    "from datetime import date\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "from neurodsp.rhythm import sliding_window_matching\n",
    "from neurodsp.utils.download import load_ndsp_data\n",
    "from neurodsp.plts.rhythm import plot_swm_pattern\n",
    "from neurodsp.plts.time_series import plot_time_series\n",
    "from neurodsp.utils import set_random_seed, create_times\n",
    "# Import listed chormap\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.dates as md\n",
    "from matplotlib import colors as mcolors\n",
    "# Scipy\n",
    "from scipy import signal\n",
    "from scipy import ndimage\n",
    "# TKinter for selecting files\n",
    "from tkinter import Tk     # from tkinter import Tk for Python 3.x\n",
    "from tkinter.filedialog import askdirectory\n",
    "#Bokeh\n",
    "from bokeh.io import output_notebook\n",
    "\n",
    "# Add my module to python path\n",
    "sys.path.append(\"../\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions\n",
    "def pipeline_peak_extraction(signal2analyse, ch,fs, spike_detection_config, verbose=False):\n",
    "        \"\"\"\n",
    "        General method to extract neural spikes and waveforms.\n",
    "        \n",
    "        Parameters\n",
    "        ------------\n",
    "        ch:                    [int] channel to analyse\n",
    "        spike_detection_config: [dict] parameters specifying the length of window, height... for detection ad extraction of neural events\n",
    "        verbose:            [int - 0,1] signal to display text information (default 1 - show text, 0 - don't show) \n",
    "\n",
    "        Returns\n",
    "        ------------\n",
    "        spikes_idx:            [array] array with indexes of neural peaks (locations) after filtering with conditions\n",
    "        waveforms:            [array, rows: number of neural peaks, columns: window with indexes around neural events] \n",
    "        spikes_vector_ampl: [array, same length as signal] amplitude of neural signal correspoding to spikes_vector_loc \n",
    "        spikes_vector_loc:    [array] numpy array with same size as signal with 1 where there's a spike and 0 otherwise\n",
    "        index_first_edge:    [array] indexes of detected peaks (positive/negative/both) before alignment to max or min\n",
    "        \"\"\"\n",
    "\n",
    "        time_start = time.time()\n",
    "\n",
    "        # ----------------------------------------------------\n",
    "        # Identify neural spikes from ENG\n",
    "        # -----------------------------------------------------\n",
    "        if verbose:\n",
    "            print(\"-------------------------------\")\n",
    "            print(\"Detecting neural events\")\n",
    "\n",
    "        spikes_idx, numunique_peak_pos, index_first_edge = \\\n",
    "            spike_detection(signal2analyse[ch], detect_method,fs, verbose=verbose, **spike_detection_config)\n",
    "        \n",
    "        waveforms, spikes_idx = get_waveforms(signal2analyse, fs, ch, spikes_idx, spike_detection_config['general']['spike_window'], spike_detection_config['general']['min_thr'], spike_detection_config['general']['half_width'])\n",
    "        spikes_vector_loc = get_spike_location(signal2analyse[ch], spikes_idx)    \n",
    "        \n",
    "        print(\"pipeline_peak_extraction completed. Time elapsed: {} seconds\".format(time.time()-time_start))\n",
    "        return spikes_idx, waveforms, spikes_vector_loc, index_first_edge\n",
    "    \n",
    "    \n",
    "def spike_detection(signal, method,fs, manual_thres=None, verbose=False, **kwargs):\n",
    "\t\t\"\"\"\n",
    "\t\tMethod for identifying neural spikes based on different methods\n",
    "\n",
    "\t\tParameters\n",
    "\t\t------------\n",
    "\t\tsignal: \t\tsignal2analyse[ch]\n",
    "\t\tmethod: \t\t[string] \n",
    "\t\tmanual_thres: \t[None or floar] If not None, then select the value specified as manual_thres\n",
    "\t\tverbose:\t\t[int - 0,1] signal to display text information (default 1 - show text, 0 - don't show) \n",
    "\n",
    "\t\tReturns\n",
    "\t\t-----------\n",
    "\t\tspikes_idx:\t\t\t[array] array with indexes of neural peaks (locations)\n",
    "\t\tnumunique_peak_pos: [int] final number of neural spikes\n",
    "\t\tindex_first_edge: \t[array] indexes of detected peaks before alignment to max or min\n",
    "\n",
    "\t\t\"\"\"\n",
    "\t\t#------------------------------------\n",
    "\t\t# Method 1: get_spikes(). \n",
    "\t\t# detect max of peaks using the find_peaks() method (using minimum distance between peaks)\n",
    "\t\t#--------------------------------------------\n",
    "\t\tif method == \"get_spikes_method\":\n",
    "\t\t\tif verbose:\n",
    "\t\t\t\tprint(method)\n",
    "\t\t\tthreshold = set_height(signal,  kwargs['general']['C'], manual_thres)\n",
    "\t\t\tprint('Have set height')\n",
    "\n",
    "            print('get positive peaks')\n",
    "\t\t\tprint(kwargs['general'])\n",
    "\t\t\t# Get positive peaks \n",
    "\t\t\tprint('calculating height')\n",
    "\t\t\tprint('Max height: %s' %(kwargs['general']['Cmax'] * np.median(np.abs(signal)/0.6745)))\n",
    "\t\t\tprint('Min height: %s' %threshold[0])\n",
    "\t\t\tkwargs['general']['find_peaks_args']['height'] = (threshold[0], kwargs['general']['Cmax'] * np.median(np.abs(signal)/0.6745))\n",
    "\t\t\tindspos = get_spikes(signal, fs, **kwargs['general'],neo=False)\n",
    "\t\t\tif verbose:\n",
    "\t\t\t\tprint('Length array spike pos from find_peaks(): %s' %len(indspos))\n",
    "\n",
    "\t\t#----------------------------------------------------------\n",
    "\t\t# Determine positive/negative/both peaks and waveforms\n",
    "\t\t#----------------------------------------------------------\n",
    "\t\tprint('Determining waveforms')\n",
    "\t\tspikes_idx=[]\n",
    "\n",
    "\t\tindex_first_edge = []\n",
    "\t\tindex_first_edge = indspos\n",
    "\t\tif verbose:\n",
    "\t\t\tprint('Number of index_first_peaks: %s' %len(index_first_edge))\n",
    "\n",
    "\t\t# Align peaks around maxima in window from the filtered signal\n",
    "\t\t# Center in windows in raw signal: This needs to be done as the wavelet \n",
    "\t\t# decomposition may slightly change the waveform, so we ensure we're picking \n",
    "\t\t# up the maximum of the original signal\n",
    "\t\tspikes_idx, numunique_peak_pos = \\\n",
    "\t\tmax_centered_peaks_optimized(signal, index_first_edge, \n",
    "\t\t\t\t\t\t\t\t\t\t\t kwargs['general']['spike_window'],\n",
    "\t\t\t\t\t\t\t\t\t\t\t verbose=verbose)\n",
    "\n",
    "\n",
    "\n",
    "\t\treturn spikes_idx, numunique_peak_pos, index_first_edge\n",
    "                                     \n",
    "def set_height(signal, C, manual_thres=None):\n",
    "\t\t\"\"\"\n",
    "\t\tThe first element is always interpreted as the minimal and \n",
    "\t\tthe second, if supplied, as the maximal required height (threshold).\n",
    "\n",
    "\t\tParameter\n",
    "\t\t----------\n",
    "\t\tsignal: [] \n",
    "\t\tC: not used (see comment)\n",
    "\t\tmanual_thres: [array of 1x2] first element is the positive and second element is the negative manual thresholds\n",
    "\n",
    "\t\tReturns\n",
    "\t\t------------\n",
    "\t\tthreshold:\t\n",
    "\n",
    "\t\tComments\n",
    "\t\t----------\n",
    "\t\tTried using C instead of np.sqrt(2*np.log(len(signal)), which is normally used for denoising wavelet\n",
    "\t\tcomponents [Diedrich2003]. However, seems to work fine before, so I'm not using C for now. \n",
    "\t\tIt's however kept commented in case I want to use it in the future\n",
    "\t\t\"\"\"\n",
    "\t\tthreshold = []\n",
    "\t\tif manual_thres is None:\n",
    "\t\t\tprint('NOT A MANUAL THRESHOLD')\n",
    "\t\t\t# divided by 0.6745, which is the 75th percentile of the standard normal distribution [15],\n",
    "\t\t\tstd_noise = np.median(np.abs(signal)/0.6745) #np.median(np.abs(signal)/0.6745)\n",
    "\t\t\tthreshold.append(std_noise*C)  #AG 02/12/2021\n",
    "\t\t\tthreshold.append(-std_noise*C)\t#AG 02/12/2021\n",
    "\t\t\tprint('np.median(np.abs(signal)/0.6745): %s' %np.median(np.abs(signal)/0.6745))\n",
    "\t\telse:\n",
    "\t\t\tthreshold.append(manual_thres[0])\n",
    "\t\t\tthreshold.append(manual_thres[1])\n",
    "\t\treturn threshold\n",
    "\n",
    "def get_waveforms(signal2analyse, fs, channel, spikes_idx, spike_window, min_thr, half_width):\n",
    "\t\t\"\"\"\n",
    "\t\tMethod to filter detected peaks based on their amplitude and width (to discard peaks with shapes different to AP),\n",
    "\t\tand extract the window around the identified neural spikes.\n",
    "\n",
    "\n",
    "\t\tParameters\n",
    "\t\t------------\n",
    "\t\tchannel:\t  [int] channel to extract waveforms from \n",
    "\t\tspikes_idx:\t  [array] array with indexes of neural peaks (locations) before filtering with conditions\n",
    "\t\tspike_window: [array 1x2] Length of window in samples: first position are samples before identified spike, second position after. From spike_detection_config['general']\n",
    "\t\tmin_thr:\t  [array 1x1] Minimum of amplitude of identified spikes. From spike_detection_config['general']\n",
    "\t\thalf_width:\t  [array 1x2] Min and max length in seconds from min to max of waveform. From spike_detection_config['general']\n",
    "\n",
    "\t\tReturns\n",
    "\t\t------------\n",
    "\t\twdws:\t\t[array, rows: number of neural peaks, columns: window with indexes around neural events] \n",
    "\t\tspikes_idx:\t[array] array with indexes of neural peaks (locations) before filtering with conditions\n",
    "\n",
    "\t\t\"\"\"\n",
    "\t\tprint(\"Getting waveforms\")\n",
    "\t\twaveforms = []\n",
    "\t\toriginal_spikes = spikes_idx\n",
    "\t\tnowidth = 0\n",
    "\t\tnoamp = 0\n",
    "\t\tindex = 0\n",
    "\n",
    "\t\twhile index in range(len(original_spikes)): \n",
    "\t\t\tp = original_spikes[index]\n",
    "\t\t\t# First filter peaks based on amplitude\n",
    "\t\t\tif np.abs(signal2analyse[channel][p])>min_thr[0] and np.abs(signal2analyse[channel][p])<min_thr[1]: \n",
    "\t\t\t\ttry:\n",
    "\t\t\t\t\tnew_window = np.arange(p - spike_window[0], p + spike_window[1] )\n",
    "\t\t\t\t\t# Second filter based on width\n",
    "\t\t\t\t\t# Calculate absolute distances from zero_crossings to max value and get the smallest of them. This is the closest zero crossing\n",
    "\t\t\t\t\tcross_zero = np.where(np.diff(np.sign(signal2analyse[channel][new_window])))[0]+1\n",
    "\t\t\t\t\tdist = np.abs(np.argmax(signal2analyse[channel][new_window])-cross_zero)\n",
    "\t\t\t\t\tmin2max = np.sort(dist)[0]\n",
    "\t\t\t\t\tif min2max > int(fs*half_width[0]) and min2max < int(fs*half_width[1]):   # Half width longer than 1 sec\n",
    "\t\t\t\t\t\twaveforms.append(signal2analyse[channel][new_window]) \t\n",
    "\t\t\t\t\t\tindex = index + 1\n",
    "\t\t\t\t\telse: \n",
    "\t\t\t\t\t\tspikes_idx.remove(p)\n",
    "\t\t\t\t\t\tnowidth = nowidth+1\n",
    "\t\t\t\t\t\t\n",
    "\t\t\t\texcept IndexError:\n",
    "\t\t\t\t\t\tprint('get_waveforms(): no zero-crossing within window ')\n",
    "\t\t\t\t\t\tspikes_idx.remove(p)\n",
    "\t\t\t\t\t#sys.exit()\n",
    "\t\t\telse: \n",
    "\t\t\t\tnoamp = noamp+1\n",
    "\t\t\t\tspikes_idx.remove(p)\n",
    "\n",
    "\t\tif waveforms:\n",
    "\t\t\twdws = np.stack(np.array(waveforms))\n",
    "\t\telse:\n",
    "\t\t\twdws = []\n",
    "\t\tprint('Peaks excluded - not appropriate width: %s' %nowidth)\n",
    "\t\tprint('Peaks excluded - not appropriate amplitude: %s' %noamp)\n",
    "\t\tprint('Len filtered peaks: %s' %len(spikes_idx))\n",
    "\t\tprint('Len wdsw peaks: %s' %len(wdws))\n",
    "\t\treturn wdws, spikes_idx\n",
    "\n",
    "\n",
    "def get_spike_location(signal, spikes_idx):  \n",
    "\t\t\"\"\"\n",
    "\t\tParameters:\n",
    "\t\t------------- \n",
    "\t\t\tsignal: input signal being analysed (signal2analyse[ch])\n",
    "\t\t\tspikes_idx: [array] 1D vector containing indexes of locations where neural spikes were identified \n",
    "\t\tReturn: \n",
    "\t\t-------------\n",
    "\t\t\tspikes_vector_loc: numpy array with same size as signal with 1 where there's a spike and 0 otherwise\n",
    "\t\t\"\"\"\n",
    "\n",
    "\t\tspikes_vector_loc = np.zeros(len(signal))\n",
    "\t\tif spikes_idx:\n",
    "\t\t\tspikes_vector_loc[np.array(list(spikes_idx))] = 1\n",
    "\t\telse:\n",
    "\t\t\tspikes_vector_loc = []\n",
    "\t\treturn spikes_vector_loc   \n",
    "\n",
    "    def filter(signal2filt,filter_ch, fs, filtername, **kargs):\n",
    "    \"\"\"\n",
    "    Method to apply filtering to recordings (ENG)\n",
    "    Note that despite the whole dataframe is passed, the algorithm only applies to the selected channels (filter_ch)\n",
    "\n",
    "    Parameters\n",
    "    ------------\n",
    "    signal2filt: [dataframe] signals to filter (columns in dataframe structure)\n",
    "    filtername:  [string] name of the filter to apply {'None', 'butter', 'fir', 'notch'}\n",
    "    kargs:     [dict] specific parameters for for the filters\n",
    "\n",
    "    Returns\n",
    "    ------------\n",
    "    filtered: [dataframe] updare the recording object with a parameter that is a dataframe with the results of the filtering\n",
    "\n",
    "    \"\"\"\n",
    "    if filtername=='None':\n",
    "        filtered = signal2filt\n",
    "        print('No filter applied!')\n",
    "        pass\n",
    "    elif filtername=='butter':\n",
    "        # Configure butterworth filter\n",
    "        kargs['fs'] = fs\n",
    "        sos = signal.butter(**kargs, output='sos')\n",
    "        filtered = signal2filt.apply(lambda x: signal.sosfilt(sos, x)\n",
    "                            if x.name in filter_ch else x)\n",
    "\n",
    "    elif filtername=='fir':\n",
    "        print(filter_ch)\n",
    "        filtered = signal2filt.apply(lambda x: FIR_smooth(x, **kargs) \n",
    "                            if x.name in filter_ch else x)\n",
    "    elif filtername=='notch':\n",
    "        filtered = signal2filt.apply(lambda x: iir_notch(x, **kargs)\n",
    "                            if x.name in filter_ch else x)\n",
    "        return filtered\n",
    "    \n",
    "def plot_freq_content(signal2plot, ch,fs, nperseg=512, max_freq=10000, ylim=None, dtformat='%M:%S.%f', figsize=(10, 15), savefigpath='', show=False):\n",
    "    \"\"\"\n",
    "    plt.specgram parameters: \n",
    "    NFFT : int\n",
    "        The number of data points used in each block for the FFT. A power 2 is most efficient. The default value is 256.\n",
    "        The benefit of a longer FFT is that you will have more frequency resolution. The number of FFT bins, the discrete \n",
    "        fequency interval of the transform will be N/2. So the frequency resolution of each bin will be the sample frequency Fs x 2/N.\n",
    "    mode : {'default', 'psd', 'magnitude', 'angle', 'phase'}\n",
    "        What sort of spectrum to use. Default is 'psd', which takes the power spectral density. \n",
    "        'magnitude' returns the magnitude spectrum. 'angle' returns the phase spectrum without unwrapping. \n",
    "        'phase' returns the phase spectrum with unwrapping.\n",
    "    scale : {'default', 'linear', 'dB'}\n",
    "        The scaling of the values in the spec. 'linear' is no scaling. 'dB' returns the values in dB scale. When mode is 'psd', \n",
    "        this is dB power (10 * log10). Otherwise this is dB amplitude (20 * log10). 'default' is 'dB' if mode is 'psd' or 'magnitude' \n",
    "        and 'linear' otherwise. This must be 'linear' if mode is 'angle' or 'phase'.\n",
    "    \"\"\"\n",
    "    # Raw signal\n",
    "    fig, ax = plt.subplots(3, 1, figsize=figsize)\n",
    "    ax[0].plot(signal2plot.index, signal2plot['ch_%s'%ch], linewidth=0.5, zorder=0)\n",
    "    ax[0].set_title('Sampling Frequency: {}Hz'.format(fs))\n",
    "    ax[0].set_xlabel('Time [s]')\n",
    "    ax[0].set_ylabel('Voltage [uV]')\n",
    "    if ylim is not None:\n",
    "        ax[0].set_ylim(ylim)\n",
    "\n",
    "    # PSD (whole dataset ferquency distribution)\n",
    "    f_data, Pxx_den_data = signal.welch(signal2plot['ch_%s'%ch], fs, nperseg=512) # nperseg\n",
    "    # ax[1].psd(data[0:sf], NFFT=1024, Fs=sf)\n",
    "    ax[1].semilogx(f_data, Pxx_den_data)\n",
    "    ax[1].set_xlabel('Frequency [Hz]')\n",
    "    ax[1].set_ylabel('PSD [V**2/Hz]')\n",
    "\n",
    "    # Spectogram (frequency content vs time)\n",
    "    # plt.specgram plots 10*np.log10(Pxx) instead of Pxx\n",
    "    plt.subplot(313)\n",
    "    powerSpectrum, freqenciesFound, time, imageAxis = plt.specgram(signal2plot['ch_%s'%ch], NFFT=nperseg, Fs=fs, mode='psd', scale='dB')\n",
    "    plt.ylabel('Spectogram \\n Frequenct [Hz]')\n",
    "    plt.xlabel('Time [s]')\n",
    "    plt.ylim([0, max_freq])\n",
    "    clb = plt.colorbar(imageAxis)\n",
    "    clb.ax.set_title('10*np.log10 \\n [dB/Hz]') \n",
    "\n",
    "    # Format axes\n",
    "    for i in range(len(ax)):\n",
    "        # Hide the right and top spines\n",
    "        ax[i].spines['right'].set_visible(False)\n",
    "        ax[i].spines['top'].set_visible(False)\n",
    "        # Only show ticks on the left and bottom spines\n",
    "        ax[i].yaxis.set_ticks_position('left')\n",
    "        ax[i].xaxis.set_ticks_position('bottom')\n",
    "    ax[0].xaxis.set_major_formatter(md.DateFormatter(dtformat))\n",
    "\n",
    "    if savefigpath!='':\n",
    "        plt.savefig(savefigpath, facecolor='w')\n",
    "\n",
    "    if show==True:\n",
    "        plt.show()\n",
    "    else:\n",
    "        print('Plot will not show')\n",
    "        plt.close()\n",
    "         \n",
    "def select_channels(channels):\n",
    "    \"\"\"\n",
    "    Method to select which channels to analyse \n",
    "    \n",
    "    Parameters\n",
    "    ------------\n",
    "    channels:     ['all' or list of numbers] list of intan channels to be analysed\n",
    "\n",
    "    Return\n",
    "    --------\n",
    "        filter_ch:    [list of string] list with the selected intan channels in string mode (starting in 'ch_')\n",
    "    \"\"\"\n",
    "\n",
    "    filter_ch = []\n",
    "    for i, ch in enumerate(channels):\n",
    "        ch = int(ch)\n",
    "        filter_ch.append('ch_%s'%ch)\n",
    "        return filter_ch\n",
    "\n",
    "class MyWaveforms:\n",
    "\tdef __init__(self, waveforms, recording, fs, spikes_vector_loc, num_clusters, path):\n",
    "\t\t\"\"\"\n",
    "\t\tspikes_vector_loc: numpy array with same size as analysed signal with 1 where there's a spike and 0 otherwise\n",
    "\t\t\"\"\"\n",
    "\t\tself.waveforms = waveforms\n",
    "\t\tself.recording = recording\n",
    "\t\tself.fs = fs\n",
    "\t\tself.num_clusters = num_clusters\n",
    "\t\tself.spikes_vector_loc = spikes_vector_loc\n",
    "\t\tself.path = path\n",
    "        \n",
    "    def noise_sd(self, signal, ch, noise_samples=[0, 1000]):\n",
    "\t\tnoise_sd = np.std(signal.iloc[int(noise_samples[0]):int(noise_samples[1])],0) #SD of noise\n",
    "\t\tprint('sd noise: %s' %noise_sd)\n",
    "\t\treturn noise_sd\n",
    "    \n",
    "    def plot_waveforms_multipleCh_mean(self, axes, ch, spike_window, ylim=[], dtformat='%S.%f'):\n",
    "\t\t\"\"\"\n",
    "\t\t\n",
    "\t\t\"\"\"\n",
    "\t\tprint('Plotting waveforms')\n",
    "\n",
    "\t\ttime = np.linspace(0, self.waveforms.shape[1] / self.fs, self.waveforms.shape[1]) * 1000\n",
    "\t\t#np.linspace(-spike_window[0]/self.fs,spike_window[1]/self.fs\n",
    "\n",
    "\t\tself.meanWave = np.mean(self.waveforms,0)\n",
    "\t\tstd_waveforms = np.std(self.waveforms, 0)\n",
    "\n",
    "\t\tspike_window = spike_window*1000\n",
    "\t\taxes.plot(time, self.meanWave, '--', )\n",
    "\t\taxes.fill_between(time,\n",
    "\t\t\t\t\t\t \tself.meanWave - std_waveforms,\n",
    "\t\t\t\t\t     \tself.meanWave + std_waveforms,\n",
    "\t\t\t\t\t\t \talpha=0.15, label='Channel: %s'%ch)\n",
    "\t\taxes.legend()\n",
    "\t\tif len(ylim)==0:\n",
    "\t\t\tpass\t\n",
    "\t\telse:\t\n",
    "\t\t\taxes.set_ylim(ylim)\n",
    "\t\t# Hide the right and top spines\n",
    "\t\taxes.spines['right'].set_visible(False)\n",
    "\t\taxes.spines['top'].set_visible(False)\n",
    "\n",
    "\t\t# Only show ticks on the left and bottom spines\n",
    "\t\taxes.yaxis.set_ticks_position('left')\n",
    "\t\taxes.xaxis.set_ticks_position('bottom')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_name = ('../datasets/')\n",
    "path = '../xx'\n",
    "\n",
    "run_first_time = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load data from two ports \n",
    "chC = 23 \n",
    "chD = 24 \n",
    "\n",
    "time_start = time.time()\n",
    "\n",
    "# Load data from pkl (saved after loading with INTAN script)\n",
    "recording = \n",
    "path = ''\n",
    "file = ''\n",
    "fs = 30000\n",
    "\n",
    "plt_ch = channels[0] #Illustrative channel to plot\n",
    "\n",
    "''' Load channels independentily first time, then load merged dataframe\n",
    "################### Load port 1 ##################################\n",
    "port = 'Port C'\n",
    "recording_C = pd.DataFrame()\n",
    "with open('%s/%s.pkl'%(path, file), 'rb') as f:\n",
    "    recording_C = pickle.load(f)\n",
    "\n",
    "################### Load port 2 ##################################\n",
    "port = 'Port D'\n",
    "recording_D = pd.DataFrame()\n",
    "with open('%s/%s.pkl'%(path, file), 'rb') as f:\n",
    "    recording_D = pickle.load(f)\n",
    "\n",
    "\n",
    "# Create directory to save figures\n",
    "if not os.path.exists('%s/figures/' %(path)):\n",
    "    os.makedirs('%s/figures/' %(path))\n",
    "\n",
    "'''\n",
    "# Merge in singke dataframe\n",
    "recording = recording_C\n",
    "recording = pd.concat([recording_C['seconds'], recording_C['ch_0'], recording_D['ch_1']], axis=1, keys=['seconds','ch_0', 'ch_1']) \n",
    "recording.name = 'original'\n",
    "\n",
    "channels = [0, 1] #0: port C , 1:portD\n",
    "\n",
    "print('Saving data into: %s/recording.pkl' %path)\n",
    "recording.to_pickle(r'%s/recording.pkl' %path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  General configuration  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "code_folding": []
   },
   "source": [
    "#### Options list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure\n",
    "config_text = []\n",
    "apply_filter = 'butter' \n",
    "detect_method = 'get_spikes_method'\n",
    "\n",
    "print('SELECTED GENERAL CONFIGURATION:')\n",
    "print('Filter: %s'%apply_filter)\n",
    "print('Detection: %s'%detect_method)\n",
    "print('Channels: %s' %channels) \n",
    "print('-------------------------------------')\n",
    "\n",
    "filter_ch = select_channels(channels) \n",
    "print('filter_ch %s' %filter_ch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specific configuration  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Spike detection config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_detection_config = {\n",
    "    'general':{\n",
    "        'cardiac': False,\n",
    "        # Length of window that containes a neural spike\n",
    "        'spike_window': [int(0.002 * fs), int(0.05 * fs)],   #[int(0.0018 * fs), int(0.0018 * fs)],  # in total 0.36s length AP: 3ms to refractory and 5ms total\n",
    "        'min_thr': [0, 100],              # Min & max of amplitude of identified spikes GUT: 10000 in gut\n",
    "        'half_width': [0.01/1000,10],  # Length in sec from zero cross to max of waveform. \n",
    "        'C': 11, \n",
    "        'Cmax': 1000,\n",
    "        'find_peaks_args': {\n",
    "        # Input to find_peaks() function:\n",
    "        # Required minimal horizontal distance (>= 1) in samples between \n",
    "        # neighbouring peaks. Smaller peaks are removed first until the \n",
    "        # condition is fulfilled for all remaining peaks.\n",
    "        'distance': int(0.0018 * 2 * fs),\n",
    "        'height': 1000\n",
    "        }\n",
    "    },\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## START ANALYSIS                                             \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Filtering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bandwidth filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure\n",
    "filt_config = {\n",
    "    'W':  [200, 7000], #  \n",
    "    'None': {},\n",
    "    'butter': {\n",
    "            'N': 9,                # The order of the filter\n",
    "            'btype': 'bandpass', #'bandpass', #'hp'  #'lowpass'     # The type of filter.\n",
    "    },      \n",
    "    'fir': {\n",
    "            'n': 4,\n",
    "    },\n",
    "    'notch': {\n",
    "            'quality_factor': 30,\n",
    "    },\n",
    "}\n",
    "\n",
    "filt_config['butter']['Wn'] = filt_config['W']\n",
    "filt_config['butter']['fs'] = fs\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Apply filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Configure\n",
    "time_start = time.time()\n",
    "signal2filter = recording \n",
    "filtered = filter(recording, filter_ch, fs, apply_filter, **filt_config[apply_filter])\n",
    "\n",
    "print(\"Time elapsed: {} seconds\".format(time.time()-time_start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Plot filtered signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text_label = 'Filtered'\n",
    "text = 'Channels after %s filtering'%apply_filter\n",
    "plot_freq_content(filtered,int(plot_ch), fs, nperseg=512, max_freq=250, ylim=[-100, 100], dtformat='%H:%M:%S',\n",
    "                         figsize=(10, 10), savefigpath='%s/figures/%s_ch%s_butter_filtering-%s.png' %(path,port,plot_ch, current_time),\n",
    "                         show=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Signal selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment if desired to continue with the filtered signal for analysis\n",
    "recording=filtered\n",
    "recording.name = 'filtered'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Signal analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Configure\n",
    "\n",
    "# Select the signal that will be used to extract the neural spikes from\n",
    "signal2analyse = -recording # Invert to detect negative peaks    \n",
    "save_waveforms = [] # To store waveform objects for more than one channel\n",
    "\n",
    "dtformat = '%S.%f' #'%H:%M:%S' '%M:%S.%f''\n",
    "\n",
    "verbose = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#-------------------------------------------------------------\n",
    "# Initialize figures\n",
    "#-------------------------------------------------------------\n",
    "time_start_analysis=time.time()\n",
    "\n",
    "\n",
    "fig2, axes_wv = plt.subplots(1, 1, figsize=(15, 8), sharex=True)\n",
    "fig2.suptitle('Waveforms', fontsize=16, family='serif')  \n",
    "axes_wv = axes_wv.flatten()\n",
    "noise_sd = []\n",
    "save_waveforms = []\n",
    "for n, j in enumerate(ch_loc): \n",
    "\n",
    "    #-------------------------------------------------------------\n",
    "    # Start pipeline of cardiac and neural peaks identification\n",
    "    #-------------------------------------------------------------\n",
    "    hr_idx, hr_vector, spikes_idx, waves, spikes_vector, spikes_vector_loc, index_first_edge = \\\n",
    "                            pipeline_peak_extraction(ch, fs, spike_detection_config,\n",
    "                                                            verbose=True)\n",
    "    # Create waveform object for processing of waveforms\n",
    "    waveforms = MyWaveforms(waves, signal2analyse, fs, spikes_vector_loc, num_clus, path)\n",
    "\n",
    "    # Compute signal to noise ratio: change 12 and 13 for baseline period in each recording\n",
    "    noise_sd.append(waveforms.noise_sd(signal2analyse[ch],ch, noise_samples=[0*fs,2*fs]))\n",
    "    waveforms.plot_waveforms_multipleCh_mean(axes_wv[0], ylim=[], dtformat=dtformat)\n",
    "    plt.show()\n",
    "\n",
    "    save_waveforms.append(waveforms)\n",
    "\n",
    "    #Save mean waveform \n",
    "    waveforms.meanWave = np.mean(waveforms.waveforms,0)\n",
    "\n",
    "\n",
    "print ('Analysis done! Time elapsed: {} seconds'.format(time.time()-time_start_analysis))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot heatmaps for each comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import seaborn\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "\n",
    "#path_gen = '../datasets/recording/Sciatic-microwires/RQ_RQ5C'\n",
    "#path_gen = '../datasets/recording/Sciatic-microwires/RQ_RQ20C'\n",
    "\n",
    "max_time = 50 #ms\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 3), sharex=True)\n",
    "m=[]\n",
    "for n in range(2):\n",
    "    print(n)\n",
    "    # glob allows to load all files in the folder\n",
    "    files = glob.glob('%s/all_results/'%(path_gen) +'/*%s.npy'%n, recursive=True)\n",
    "    files_2 = sorted(files)\n",
    "    size = len(files)\n",
    "    print(size)\n",
    "    # Create arrays to store all the data\n",
    "    waves = np.empty(0)\n",
    "    # Run over all files\n",
    "    for num,file in enumerate(files_2):\n",
    "        print(file)\n",
    "        #new_wave = np.load('%s/all_results/'%(path_gen) + 'cluster_df_num%s_*_%s.npy'%(num,n))[0:int(0.035*30000)]\n",
    "        new_wave = np.load(file)[0:int(max_time/1000*30000)]\n",
    "        #print(new_wave)\n",
    "        normalized_wave = new_wave / np.linalg.norm(new_wave)\n",
    "        waves = np.append(waves, normalized_wave, axis=0)\n",
    "        m.append(waves.max())\n",
    "    waves = np.reshape(waves, [size, len(new_wave) ])\n",
    "    # Plot heatmap\n",
    "    seaborn.heatmap(waves, cmap=sns.diverging_palette(0, 255, s=110, l=55, sep=8, n=256),  ax=axes[n], vmin=-0.15, vmax=0.15) # vmin=-m[0], vmax=m[0])# , s=100, l=55\n",
    "plt.show()\n",
    "\n",
    "# Get current time for saving (avoid overwriting)\n",
    "now = datetime.datetime.now()\n",
    "current_time = now.strftime(\"%d%m%Y_%H%M%S\")\n",
    "fig.savefig('%s/all_waveforms_new-%s.svg' %(path_gen, current_time), facecolor='w')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "301.997px",
    "width": "729.991px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
